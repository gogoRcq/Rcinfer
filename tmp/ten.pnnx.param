7767517
29 28
pnnx.Input               pnnx_input_0             0 1 0 #0=(2,3,128,128)f32
nn.Conv2d                conv1                    1 1 0 1 bias=True dilation=(1,1) groups=1 in_channels=3 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,3,3,3)f32 #0=(2,3,128,128)f32 #1=(2,64,128,128)f32
nn.ReLU                  relu1                    1 1 1 2 #1=(2,64,128,128)f32 #2=(2,64,128,128)f32
nn.Conv2d                conv1_1                  1 1 2 3 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #2=(2,64,128,128)f32 #3=(2,64,128,128)f32
nn.ReLU                  relu1_1                  1 1 3 4 #3=(2,64,128,128)f32 #4=(2,64,128,128)f32
nn.Conv2d                conv1_2                  1 1 4 5 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #4=(2,64,128,128)f32 #5=(2,64,128,128)f32
pnnx.Expression          pnnx_expr_7              2 1 2 5 6 expr=add(@0,@1) #2=(2,64,128,128)f32 #5=(2,64,128,128)f32 #6=(2,64,128,128)f32
nn.ReLU                  relu2                    1 1 6 7 #6=(2,64,128,128)f32 #7=(2,64,128,128)f32
nn.Conv2d                conv2_11                 1 1 7 8 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(128)f32 @weight=(128,64,3,3)f32 #7=(2,64,128,128)f32 #8=(2,128,64,64)f32
nn.ReLU                  relu2_11                 1 1 8 9 #8=(2,128,64,64)f32 #9=(2,128,64,64)f32
nn.Conv2d                conv2_12                 1 1 9 10 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,3,3)f32 #9=(2,128,64,64)f32 #10=(2,128,64,64)f32
nn.Conv2d                conv2_21                 1 1 7 11 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(2,2) @bias=(128)f32 @weight=(128,64,1,1)f32 #7=(2,64,128,128)f32 #11=(2,128,64,64)f32
pnnx.Expression          pnnx_expr_5              2 1 10 11 12 expr=add(@0,@1) #10=(2,128,64,64)f32 #11=(2,128,64,64)f32 #12=(2,128,64,64)f32
nn.ReLU                  relu3                    1 1 12 13 #12=(2,128,64,64)f32 #13=(2,128,64,64)f32
nn.Conv2d                conv3_11                 1 1 13 14 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(256)f32 @weight=(256,128,3,3)f32 #13=(2,128,64,64)f32 #14=(2,256,32,32)f32
nn.ReLU                  relu3_11                 1 1 14 15 #14=(2,256,32,32)f32 #15=(2,256,32,32)f32
nn.Conv2d                conv3_12                 1 1 15 16 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,3,3)f32 #15=(2,256,32,32)f32 #16=(2,256,32,32)f32
nn.Conv2d                conv3_21                 1 1 13 17 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(2,2) @bias=(256)f32 @weight=(256,128,1,1)f32 #13=(2,128,64,64)f32 #17=(2,256,32,32)f32
pnnx.Expression          pnnx_expr_3              2 1 16 17 18 expr=add(@0,@1) #16=(2,256,32,32)f32 #17=(2,256,32,32)f32 #18=(2,256,32,32)f32
nn.ReLU                  relu4                    1 1 18 19 #18=(2,256,32,32)f32 #19=(2,256,32,32)f32
nn.Conv2d                conv4_11                 1 1 19 20 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(512)f32 @weight=(512,256,3,3)f32 #19=(2,256,32,32)f32 #20=(2,512,16,16)f32
nn.ReLU                  relu4_11                 1 1 20 21 #20=(2,512,16,16)f32 #21=(2,512,16,16)f32
nn.Conv2d                conv4_12                 1 1 21 22 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,512,3,3)f32 #21=(2,512,16,16)f32 #22=(2,512,16,16)f32
nn.Conv2d                conv4_21                 1 1 19 23 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=512 padding=(0,0) padding_mode=zeros stride=(2,2) @bias=(512)f32 @weight=(512,256,1,1)f32 #19=(2,256,32,32)f32 #23=(2,512,16,16)f32
pnnx.Expression          pnnx_expr_1              2 1 22 23 24 expr=add(@0,@1) #22=(2,512,16,16)f32 #23=(2,512,16,16)f32 #24=(2,512,16,16)f32
nn.ReLU                  relu5                    1 1 24 25 #24=(2,512,16,16)f32 #25=(2,512,16,16)f32
nn.AdaptiveAvgPool2d     avgpool                  1 1 25 26 output_size=(1,1) #25=(2,512,16,16)f32 #26=(2,512,1,1)f32
Tensor.view              Tensor.view_0            1 1 26 27 shape=(2,-1) $input=26 #26=(2,512,1,1)f32 #27=(2,512)f32
pnnx.Output              pnnx_output_0            1 0 27 #27=(2,512)f32
